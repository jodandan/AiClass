{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f65c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "import zipfile\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "# set seed to reproduce similar results\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95db17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 디렉토리 설정\n",
    "data_dir = \"C:/Users/wdd45/OneDrive/바탕 화면/딥러닝응용/human/UCI HAR Dataset/UCI HAR Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2412bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩 및 전처리\n",
    "def load_HAR_data(data_dir):\n",
    "    train_signals, train_labels, test_signals, test_labels = [], [], [], []\n",
    "\n",
    "    for signal_type in [\"train\", \"test\"]:\n",
    "        for signal in [\"Inertial Signals/total_acc_x_\", \"Inertial Signals/body_acc_x_\", \"Inertial Signals/body_gyro_x_\"]:\n",
    "            filename = f\"{data_dir}/{signal_type}/{signal}{signal_type}.txt\"\n",
    "            data = pd.read_csv(filename, delim_whitespace=True, header=None).values\n",
    "            if \"train\" in signal_type:\n",
    "                train_signals.append(data)\n",
    "            else:\n",
    "                test_signals.append(data)\n",
    "\n",
    "        labels_filename = f\"{data_dir}/{signal_type}/y_{signal_type}.txt\"\n",
    "        labels = pd.read_csv(labels_filename, header=None, names=[\"Activity\"]).values\n",
    "        if \"train\" in signal_type:\n",
    "            train_labels.append(labels)\n",
    "        else:\n",
    "            test_labels.append(labels)\n",
    "\n",
    "    train_signals = np.transpose(np.array(train_signals), (1, 2, 0))\n",
    "    test_signals = np.transpose(np.array(test_signals), (1, 2, 0))\n",
    "    train_labels = train_labels[0]\n",
    "    test_labels = test_labels[0]\n",
    "\n",
    "    return train_signals, train_labels, test_signals, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e779bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로딩\n",
    "train_signals, train_labels, test_signals, test_labels = load_HAR_data(data_dir)\n",
    "\n",
    "# 레이블 수정 (0부터 시작하도록)\n",
    "train_labels = train_labels - 1\n",
    "test_labels = test_labels - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76910ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화\n",
    "train_signals = (train_signals - np.mean(train_signals)) / np.std(train_signals)\n",
    "test_signals = (test_signals - np.mean(test_signals)) / np.std(test_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef3e218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 훈련 및 검증 세트로 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_signals, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a60dce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 적절하게 변환\n",
    "X_train = X_train.transpose(0, 2, 1)\n",
    "X_val = X_val.transpose(0, 2, 1)\n",
    "test_signals = test_signals.transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "635ad4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 아키텍처 정의 (입력 형태 수정)\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(MaxPooling1D(pool_size=1))  # pool_size를 (2,) 또는 (3,) 등으로 수정\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))  # 클래스 수에 따라 조정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bebe7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41045e0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1, 64)             24640     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1, 64)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,734\n",
      "Trainable params: 33,734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 요약\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b543b496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000028AC322EF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000028AC322EF78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "182/184 [============================>.] - ETA: 0s - loss: 0.7777 - accuracy: 0.6636WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000028AC5D12AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000028AC5D12AF8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "184/184 [==============================] - 1s 3ms/step - loss: 0.7754 - accuracy: 0.6643 - val_loss: 0.5807 - val_accuracy: 0.7267\n",
      "Epoch 2/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.7755 - val_loss: 0.5193 - val_accuracy: 0.7356\n",
      "Epoch 3/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8019 - val_loss: 0.4436 - val_accuracy: 0.7865\n",
      "Epoch 4/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8181 - val_loss: 0.4476 - val_accuracy: 0.7859\n",
      "Epoch 5/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8363 - val_loss: 0.4147 - val_accuracy: 0.7995\n",
      "Epoch 6/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8395 - val_loss: 0.3990 - val_accuracy: 0.7933\n",
      "Epoch 7/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.8492 - val_loss: 0.3762 - val_accuracy: 0.8083\n",
      "Epoch 8/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.8555 - val_loss: 0.3861 - val_accuracy: 0.8069\n",
      "Epoch 9/10\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 0.2635 - accuracy: 0.8577 - val_loss: 0.4202 - val_accuracy: 0.7947\n",
      "Epoch 10/10\n",
      "184/184 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.8589 - val_loss: 0.3788 - val_accuracy: 0.8015\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "024b6abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7954\n",
      "Test accuracy: 79.54%\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_accuracy = model.evaluate(test_signals, test_labels)\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f5e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
