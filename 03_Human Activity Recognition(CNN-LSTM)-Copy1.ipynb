{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6bbaa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "import zipfile\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "def load_file(filepath):\n",
    "    dataframe = pd.read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    "\n",
    "\n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    loaded = np.dstack(loaded)\n",
    "    return loaded\n",
    "\n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    #filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + \"C:/Users/wdd45/OneDrive/바탕 화면/딥러닝응용/human/UCI HAR Dataset/UCI HAR Dataset/\")\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + \"C:/Users/wdd45/OneDrive/바탕 화면/딥러닝응용/human/UCI HAR Dataset/UCI HAR Dataset/\")\n",
    "    \n",
    "    #zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    #one hot encode y\n",
    "    trainy_one_hot = to_categorical(trainy)\n",
    "    testy_one_hot = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, trainy_one_hot.shape, testX.shape, testy.shape, testy_one_hot.shape)\n",
    "    return trainX, trainy, trainy_one_hot, testX, testy, testy_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b5501046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7352, 128, 6) (7352, 1) (7352, 6) (2947, 128, 6) (2947, 1) (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainy, trainy_one_hot, testX, testy, testy_one_hot = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f81c38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy_one_hot.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "27451545",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "90afa344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "batch_size = 64\n",
    "validation_split = 0.2\n",
    "train_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bcfe7b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000012DE046A948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000012DE046A948> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "92/92 [==============================] - ETA: 0s - loss: 0.5883 - accuracy: 0.7504WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000012DE6BACE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000012DE6BACE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "92/92 [==============================] - 12s 101ms/step - loss: 0.5883 - accuracy: 0.7504 - val_loss: 0.7272 - val_accuracy: 0.8280\n",
      "Epoch 2/10\n",
      "92/92 [==============================] - 9s 94ms/step - loss: 0.2317 - accuracy: 0.9038 - val_loss: 0.5852 - val_accuracy: 0.8960\n",
      "Epoch 3/10\n",
      "92/92 [==============================] - 8s 91ms/step - loss: 0.1496 - accuracy: 0.9378 - val_loss: 0.5112 - val_accuracy: 0.9021\n",
      "Epoch 4/10\n",
      "92/92 [==============================] - 9s 94ms/step - loss: 0.1214 - accuracy: 0.9480 - val_loss: 0.5384 - val_accuracy: 0.9028\n",
      "Epoch 5/10\n",
      "92/92 [==============================] - 9s 99ms/step - loss: 0.1054 - accuracy: 0.9537 - val_loss: 0.5868 - val_accuracy: 0.9116\n",
      "Epoch 6/10\n",
      "92/92 [==============================] - 9s 96ms/step - loss: 0.1080 - accuracy: 0.9544 - val_loss: 0.6571 - val_accuracy: 0.8872\n",
      "Epoch 7/10\n",
      "92/92 [==============================] - 9s 94ms/step - loss: 0.1023 - accuracy: 0.9563 - val_loss: 0.5359 - val_accuracy: 0.9116\n",
      "Epoch 8/10\n",
      "92/92 [==============================] - 9s 94ms/step - loss: 0.0860 - accuracy: 0.9638 - val_loss: 0.5974 - val_accuracy: 0.9007\n",
      "Epoch 9/10\n",
      "92/92 [==============================] - 9s 95ms/step - loss: 0.0834 - accuracy: 0.9619 - val_loss: 0.5579 - val_accuracy: 0.9055\n",
      "Epoch 10/10\n",
      "92/92 [==============================] - 8s 89ms/step - loss: 0.0949 - accuracy: 0.9563 - val_loss: 0.6163 - val_accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainy_one_hot, epochs=train_epochs, batch_size=batch_size, verbose=True, validation_split=validation_split, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f90685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3ec252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a3d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314fcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2cd97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b556e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d548f26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db3ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a81ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
