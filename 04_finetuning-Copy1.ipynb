{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e6f6068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the path to your CSV file\n",
    "file_path = \"C:/Users/wdd45/OneDrive/바탕 화면/딥러닝응용/\\pamap2.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "100d405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0cd62828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique classes: 8\n",
      "Unique classes: [ 1  2  3 12 13  4  7  5]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'target_column_name' is the name of your target column\n",
    "unique_classes = data['activityID'].unique()\n",
    "num_classes = len(unique_classes)\n",
    "\n",
    "print(f'Number of unique classes: {num_classes}')\n",
    "print(f'Unique classes: {unique_classes}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "06a3e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'activityID' with the actual name of your target column\n",
    "y = data['activityID']\n",
    "\n",
    "# Define the features (X) by dropping the target column from the DataFrame\n",
    "X = data.drop(columns=['activityID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "de131b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b2095a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2f80ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an MLP model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Specify the number of output classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cb03213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "edffa6ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000275B0FCA558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000275B0FCA558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000275B0FCA558> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2952/2963 [============================>.] - ETA: 0s - loss: 0.3382 - accuracy: 0.8760WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000275B18705E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000275B18705E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000275B18705E8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2963/2963 [==============================] - 9s 3ms/step - loss: 0.3376 - accuracy: 0.8763 - val_loss: 0.1082 - val_accuracy: 0.9617\n",
      "Epoch 2/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.1482 - accuracy: 0.9458 - val_loss: 0.0775 - val_accuracy: 0.9693\n",
      "Epoch 3/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.1168 - accuracy: 0.9568 - val_loss: 0.0543 - val_accuracy: 0.9810\n",
      "Epoch 4/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.1000 - accuracy: 0.9634 - val_loss: 0.0469 - val_accuracy: 0.9841\n",
      "Epoch 5/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.0914 - accuracy: 0.9669 - val_loss: 0.0406 - val_accuracy: 0.9854\n",
      "Epoch 6/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.0822 - accuracy: 0.9703 - val_loss: 0.0356 - val_accuracy: 0.9879\n",
      "Epoch 7/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.0789 - accuracy: 0.9716 - val_loss: 0.0334 - val_accuracy: 0.9887\n",
      "Epoch 8/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.0733 - accuracy: 0.9739 - val_loss: 0.0346 - val_accuracy: 0.9872\n",
      "Epoch 9/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.0718 - accuracy: 0.9745 - val_loss: 0.0303 - val_accuracy: 0.9889\n",
      "Epoch 10/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.0658 - accuracy: 0.9768 - val_loss: 0.0274 - val_accuracy: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x275b0fd76c8>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on your data\n",
    "# Update the 'activityID' column to have values within the valid class range\n",
    "y_train = y_train % num_classes\n",
    "y_test = y_test % num_classes\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d97ee2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# Load your existing model\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0e970fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers of the base model\n",
    "model.layers[0].trainable = False  # Assuming you want to freeze the first layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "081a6af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# Compile the model (You may need to adjust the learning rate)\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3a6ed5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000275B423BCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000275B423BCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000275B423BCA8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2941/2963 [============================>.] - ETA: 0s - loss: 0.5895 - accuracy: 0.7748WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000275B1C1B1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000275B1C1B1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000275B1C1B1F8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.5885 - accuracy: 0.7752 - val_loss: 0.2862 - val_accuracy: 0.9116\n",
      "Epoch 2/10\n",
      "2963/2963 [==============================] - 7s 2ms/step - loss: 0.4179 - accuracy: 0.8427 - val_loss: 0.2335 - val_accuracy: 0.9259\n",
      "Epoch 3/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.3714 - accuracy: 0.8607 - val_loss: 0.2114 - val_accuracy: 0.9266\n",
      "Epoch 4/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.3534 - accuracy: 0.8669 - val_loss: 0.1846 - val_accuracy: 0.9409\n",
      "Epoch 5/10\n",
      "2963/2963 [==============================] - 7s 2ms/step - loss: 0.3428 - accuracy: 0.8697 - val_loss: 0.1872 - val_accuracy: 0.9393\n",
      "Epoch 6/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.3374 - accuracy: 0.8723 - val_loss: 0.1822 - val_accuracy: 0.9384\n",
      "Epoch 7/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.3288 - accuracy: 0.8749 - val_loss: 0.1795 - val_accuracy: 0.9380\n",
      "Epoch 8/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.3278 - accuracy: 0.8758 - val_loss: 0.1757 - val_accuracy: 0.9455\n",
      "Epoch 9/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.3197 - accuracy: 0.8776 - val_loss: 0.1773 - val_accuracy: 0.9419\n",
      "Epoch 10/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.3153 - accuracy: 0.8803 - val_loss: 0.1661 - val_accuracy: 0.9461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x275b19f0b08>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on your data\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e0427110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's fine-tune the model by unfreezing and retraining it\n",
    "# Unfreeze the layers of the base model\n",
    "model.layers[0].trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "43844a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "# Recompile the model to apply changes\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ec2d269a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000275B0FFDE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000275B0FFDE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000275B0FFDE58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2962/2963 [============================>.] - ETA: 0s - loss: 0.2378 - accuracy: 0.9123WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000275B1AD9F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000275B1AD9F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000275B1AD9F78> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.2378 - accuracy: 0.9123 - val_loss: 0.1022 - val_accuracy: 0.9622\n",
      "Epoch 2/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.1765 - accuracy: 0.9350 - val_loss: 0.0779 - val_accuracy: 0.9683\n",
      "Epoch 3/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.1493 - accuracy: 0.9454 - val_loss: 0.0686 - val_accuracy: 0.9753\n",
      "Epoch 4/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.1279 - accuracy: 0.9532 - val_loss: 0.0545 - val_accuracy: 0.9797\n",
      "Epoch 5/10\n",
      "2963/2963 [==============================] - 9s 3ms/step - loss: 0.1133 - accuracy: 0.9581 - val_loss: 0.0487 - val_accuracy: 0.9811\n",
      "Epoch 6/10\n",
      "2963/2963 [==============================] - 9s 3ms/step - loss: 0.1065 - accuracy: 0.9611 - val_loss: 0.0444 - val_accuracy: 0.9851\n",
      "Epoch 7/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.0973 - accuracy: 0.9651 - val_loss: 0.0381 - val_accuracy: 0.9862\n",
      "Epoch 8/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.0908 - accuracy: 0.9678 - val_loss: 0.0363 - val_accuracy: 0.9877\n",
      "Epoch 9/10\n",
      "2963/2963 [==============================] - 8s 3ms/step - loss: 0.0843 - accuracy: 0.9702 - val_loss: 0.0322 - val_accuracy: 0.9883\n",
      "Epoch 10/10\n",
      "2963/2963 [==============================] - 9s 3ms/step - loss: 0.0815 - accuracy: 0.9709 - val_loss: 0.0338 - val_accuracy: 0.9877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x275b1d22508>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrain the model to perform fine-tuning\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147d07e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
